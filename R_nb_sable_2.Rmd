---
title: "R Notebook"
output: html_notebook
---
FIRST: run the stats_proj_sablefish scriptfile.

For some reason, it's not working well with Rnotebook.

So, run that scriptfile first, and now I'll try working in R notebook.


Treat the data as geostatisitcal data
conduct a Spatial Logistic Regression
and use the spBayes package

My datafile name is: Sable_geo

So, logistic regression means we either use 0 or 1 for the data. I think I'll need to manipulate the Sable_geo data to reflect this.

```{r}
names(Sable_geo)
Sable_geo$data
length(Sable_geo$data)

#I can do this with a for loop.. or with mutate
Sable_geo_df_2 <- as.data.frame(Sable_geo)
Sable_geo_df_binary <- Sable_geo_df_2 %>% mutate(data = ifelse(data>0, 1, 0))
length(Sable_geo_df_binary$data)

Sable_geo_binary <- as.geodata(Sable_geo_df_binary)
##warning that there's some overlapping locations. I shold think about getting rid of duplicates?
```


Ok so now I have a binary dataframe and binary geodataframe. We can do logistic regression on this...
It uses the logit tranformation


Might be useful to do this as bayes and not based methods
Where's my plot of alaska??
IDK
There's a ggplot way.
I think I can skip this
Reference: https://hughst.github.io/week-6/


Ooh, I do make a model!
A linear model or a glm?
GLM
```{r}
names(Sable_geo_df_binary)
glm_mod_1 <- glm(data ~ LONGITUDE + LATITUDE, data=Sable_geo_df_binary, family=binomial())
summary(glm_mod_1)

ggplot() + geom_point(aes(glm_mod_1$fitted, Sable_geo_df_binary$data))
```
I think glms are not in bayes though
Looks like there are spatial trends

```{r}

```


AND I need to check for spatial autocorrelation


OK... Trying spbayes
```{r}
library(spBayes)

```

Which fucntions do I need?
spMvGLm fits multivariate Bayesian generalized linear spatioal regression models
-> might be this one

spGLM - > best one yet. OR GLM USE THIS ONE!!

```{r}
?spGLM
#how to do a spatial logitic regression with this thoug?
#phi <-
#sigma_sq <-

```


Before I do this tho, I think I need to go through the process where I esitmate a phi and sigma squared without using bayesian techniques. I think this is HW 3 and 4, with scallops and wolfcamp
FREQUENTIST WORLDVIEW
```{r}
#fit a logistic model?
sable_glm_trend_1 <- glm(data ~ LONGITUDE + LATITUDE, data=Sable_geo_df_binary, family=binomial(link=logit))

sable_glm_1_int <-  glm(data ~ LONGITUDE + LATITUDE + LONGITUDE:LATITUDE, data=Sable_geo_df_binary, family=binomial(link=logit))

sable_glm_trend_2_int <- glm(data ~ LONGITUDE + LATITUDE + I(LONGITUDE^2) + I(LATITUDE^2) + LONGITUDE:LATITUDE, data=Sable_geo_df_binary, family=binomial(link=logit))

sable_glm_2_noint <- glm(data ~ LONGITUDE + LATITUDE + I(LONGITUDE^2) + I(LATITUDE^2) , data=Sable_geo_df_binary, family=binomial(link=logit))

sable_glm_no_trend <- glm(data ~ 1, data=Sable_geo_df_binary, family=binomial(link=logit))

summary(sable_glm_trend_1) #all the things are singificant
summary(sable_glm_1_int) #interactions are a thing tho
summary(sable_glm_trend_2_int)#none the things are significant
summary(sable_glm_2_noint) #this one is really good actually. but I;d probably drop LONG^2 if given the option
summary(sable_glm_no_trend) #nope
plot(Sable_geo_binary)

max(Sable_geo_df_binary$LATITUDE)

boxwid <- 1

my_grid <- pred_grid(  #MAKE THE PREDICTED GRID BE NICE ROUND NUMBERS... choose a nult of the boxwidth
  c(-10, 15),
  c(50, 55),
  by=boxwid
) #i think these values are fine



dim(my_grid)

my_variog_sable<- variog(Sable_geo_binary, trend="1st") 
my_variog_sable_2<- variog(Sable_geo_binary, trend="2nd") 

plot(my_variog_sable)
plot(my_variog_sable_2)
#
#both look weird
##gonna roll with trend=1st for now.

##Variofit for the WLS estimate
my_WLS_sable <- variofit(my_variog_sable,
                        ini.cov.pars = c(0.11, 10), #sill, then range estimates
                        cov.model="exponential",
                        fix.nugget=F,
                        max.dist = 300 #plot gets weird after 300
                        )

##plot it over your variog
plot(my_variog_sable)
lines(my_WLS_sable) #looks like a good fit to me.
```




AND check for spatial autocorrelation!! How to do this again? A variogram??

BACK To BAYESIAN
spGLM
```{r}
#my binary dataframe:
##Sable_geo_df_binary

phi <- 3/50 #i think I need to find estimates for these
sigma.sq <- 2


####some other stuff above, not sure how important
m.1 <- spGLM(data~LONGITUDE + LATITUDE, family="binomial", coords=coords, weights=weights, starting=list("beta"=beta.starting, "phi"=0.06,"sigma.sq"=1, "w"=0),
                 tuning=list("beta"=beta.tuning, "phi"=0.5, "sigma.sq"=0.5, "w"=0.5),
priors=list("beta.Normal"=list(0,10), "phi.Unif"=c(0.03, 0.3), "sigma.sq.IG"=c(2, 1)), amcmc=list("n.batch"=n.batch, "batch.length"=batch.length, "accept.rate"=0.43),
                 cov.model="exponential", verbose=TRUE, n.report=10)
```


```{r}
library(spBayes)
?spGLM

m.2 <- spGLM(data~LONGITUDE + LATITUDE, family="binomial", coords=Sable_geo_binary$coords,  starting=list("beta"=beta.starting, "phi"=0.06,"sigma.sq"=1), #need to add somehthing here!! ##what is beta starting
                 tuning=list("beta"=beta.tuning, "phi"=0.5, "sigma.sq"=0.5),
priors=list("beta.Normal"=list(0,10), "phi.Unif"=c(0.03, 0.3), "sigma.sq.IG"=c(2, 1)), amcmc=list("n.batch"=n.batch, "batch.length"=batch.length, "accept.rate"=0.43),
                 cov.model="exponential", verbose=TRUE, n.report=10)
                 
                 
                 
m.3 <- spGLM(data~LONGITUDE + LATITUDE, family="binomial", coords=Sable_geo_binary$coords, data=Sable_geo_df_binary, n.samples = 100, cov.model="exponential",
             starting=list("phi"=0.5,"sigma.sq"=1), priors=list("phi.Unif"=c(0.03, 0.3), "sigma.sq.IG"=c(2,1)), tuning=list("phi"=0.5, "sigma.sq"=0.5, "beta"= )) # starting=list("beta"=beta.starting, "phi"=0.06,"sigma.sq"=1), #need to add somehthing here!! ##what is beta starting
                # tuning=list("beta"=beta.tuning, "phi"=0.5, "sigma.sq"=0.5),
#priors=list("beta.Normal"=list(0,10), "phi.Unif"=c(0.03, 0.3), "sigma.sq.IG"=c(2, 1)), amcmc=list("n.batch"=n.batch, "batch.length"=batch.length, "accept.rate"=0.43),
                 #cov.model="exponential", verbose=TRUE, n.report=10)
```

Epiphany: bayesian 04/06/22
p. 37 of spBayes documentation
```{r}
fit <- glm(data~LONGITUDE + LATITUDE, family=binomial(link=logit), data=Sable_geo_df_binary)
beta.starting <- coef(fit)
beta.tuning <- t(chol(vcov(fit)))


n.batch <- 200
batch.length <- 50
n.samples <- n.batch*batch.length

m.4 <- spGLM(data~LONGITUDE + LATITUDE, family="binomial", coords=Sable_geo_binary$coords, data=Sable_geo_df_binary, n.samples = 100, cov.model="exponential",
             starting=list("phi"=0.5,"sigma.sq"=1, "beta"=beta.starting), priors=list("phi.Unif"=c(0.03, 0.3), "sigma.sq.IG"=c(2,1)), tuning=list("phi"=0.5, "sigma.sq"=0.5, "beta"= beta.tuning, "w" = 0.05),
  amcmc=list("n.batch"=n.batch, "batch.length"=batch.length, "accept.rate"=0.43),
                 verbose=TRUE, n.report=10)

```

Ok, I made some progress!! Now ley;s figure out which starting values to use for w, phi, sigmasq
Which is the... rnage parameter (phi), w is something I forgot, and sigma sq is the sill, I think!
```{r}

```

